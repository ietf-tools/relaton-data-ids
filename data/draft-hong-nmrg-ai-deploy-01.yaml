---
schema-version: v1.2.3
id: draft-hong-nmrg-ai-deploy-01
title:
- content: Considerations of deploying AI services in a distributed approach
  language:
  - en
  script:
  - Latn
  format: text/plain
link:
- content: https://datatracker.ietf.org/doc/html/draft-hong-nmrg-ai-deploy-01
  type: src
type: standard
docid:
- id: draft-hong-nmrg-ai-deploy-01
  type: Internet-Draft
  primary: true
- id: I-D.hong-nmrg-ai-deploy
  type: IETF
  scope: anchor
docnumber: I-D.hong-nmrg-ai-deploy
date:
- type: published
  value: '2022-07-11'
contributor:
- person:
    name:
      given:
        forename:
        - language:
          - en
          initial: "Y"
        formatted_initials:
          content: Y.
          language:
          - en
      surname:
        content: Hong
        language:
        - en
      completename:
        content: Yong-Geun Hong
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Daejeon University
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - language:
          - en
          initial: J
        formatted_initials:
          content: J.
          language:
          - en
      surname:
        content: Youn
        language:
        - en
      completename:
        content: Joo-Sang Youn
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: DONG-EUI Univ
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - language:
          - en
          initial: H
        formatted_initials:
          content: H.
          language:
          - en
      surname:
        content: Kahng
        language:
        - en
      completename:
        content: Hyun-Kook Kahng
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Korea University
  role:
  - type: author
version:
- draft: '01'
revdate: '2022-07-11'
language:
- en
script:
- Latn
abstract:
- content: "<p>As the development of AI technology matured and AI technology began
    to be applied in various fields, AI technology is changed from running only on
    very high-performance servers with small hardware, including microcontrollers,
    low-performance CPUs and AI chipsets. In this document, we consider how to configure
    the system in terms of AI inference service to provide AI service in a distributed
    approach. Also, we describe the points to be considered in the environment where
    a client connects to a cloud server and an edge device and requests an AI service.</p>"
  language:
  - en
  script:
  - Latn
  format: text/html
relation:
- type: updates
  bibitem:
    id: draft-hong-nmrg-ai-deploy-00
    docid:
    - id: draft-hong-nmrg-ai-deploy-00
      type: Internet-Draft
      primary: true
    formattedref:
      content: draft-hong-nmrg-ai-deploy-00
      format: text/plain
- type: updatedBy
  bibitem:
    id: draft-hong-nmrg-ai-deploy-05
    docid:
    - id: draft-hong-nmrg-ai-deploy-05
      type: Internet-Draft
      primary: true
    formattedref:
      content: draft-hong-nmrg-ai-deploy-05
      format: text/plain
series:
- type: main
  title:
    content: Internet-Draft
    language:
    - en
    script:
    - Latn
    format: text/plain
  number: draft-hong-nmrg-ai-deploy-01
doctype: internet-draft
ext:
  schema-version: v1.0.1
