---
schema-version: v1.2.3
id: draft-xu-rtgwg-fare-in-sun
title:
- content: Fully Adaptive Routing Ethernet in Scale-Up Networks
  language:
  - en
  script:
  - Latn
  format: text/plain
docid:
- id: draft-xu-rtgwg-fare-in-sun
  type: Internet-Draft
  primary: true
abstract:
- content: "<p>The Mixture of Experts (MoE) has become a dominant paradigm in transformer-based
    artificial intelligence (AI) large language models (LLMs). It is widely adopted
    in both distributed training and distributed inference. Furthermore, the disaggregation
    of the prefill and decode phases is highly beneficial and is considered a best
    practice for distributed inference models; however, this approach depends on highly
    efficient Key-Value (KV) cache synchronization. To enable efficient expert parallelization
    and KV cache synchronization across dozens or even hundreds of Graphics Processing
    Units (GPUs) in MoE architectures, an ultra-high- throughput, ultra-low-latency
    AI scale-up network (SUN) that can efficiently distribute data across all network
    planes is critical. This document describes how to extend the Weighted Equal-Cost
    Multi- Path (WECMP) load-balancing mechanism, referred to as Fully Adaptive Routing
    Ethernet (FARE), which was originally designed for scale-out networks, to scale-up
    networks.</p>"
  language:
  - en
  script:
  - Latn
  format: text/html
relation:
- type: includes
  bibitem:
    id: draft-xu-rtgwg-fare-in-sun-00
    docid:
    - id: draft-xu-rtgwg-fare-in-sun-00
      type: Internet-Draft
      primary: true
    formattedref:
      content: draft-xu-rtgwg-fare-in-sun-00
      format: text/plain
- type: includes
  bibitem:
    id: draft-xu-rtgwg-fare-in-sun-01
    docid:
    - id: draft-xu-rtgwg-fare-in-sun-01
      type: Internet-Draft
      primary: true
    formattedref:
      content: draft-xu-rtgwg-fare-in-sun-01
      format: text/plain
ext:
  schema-version: v1.0.1
