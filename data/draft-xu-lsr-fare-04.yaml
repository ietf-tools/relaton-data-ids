---
schema-version: v1.2.3
id: draft-xu-lsr-fare-04
title:
- content: Fully Adaptive Routing Ethernet using LSR
  language:
  - en
  script:
  - Latn
  format: text/plain
link:
- content: https://datatracker.ietf.org/doc/html/draft-xu-lsr-fare-04
  type: src
type: standard
docid:
- id: draft-xu-lsr-fare-04
  type: Internet-Draft
  primary: true
- id: I-D.xu-lsr-fare
  type: IETF
  scope: anchor
docnumber: I-D.xu-lsr-fare
date:
- type: published
  value: '2025-05-21'
contributor:
- person:
    name:
      given:
        forename:
        - content: Xiaohu
          language:
          - en
        - language:
          - en
          initial: X
        formatted_initials:
          content: X.
          language:
          - en
      surname:
        content: Xu
        language:
        - en
      completename:
        content: Xiaohu Xu
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: China Mobile
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Shraddha
          language:
          - en
        - language:
          - en
          initial: S
        formatted_initials:
          content: S.
          language:
          - en
      surname:
        content: Hegde
        language:
        - en
      completename:
        content: Shraddha Hegde
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Juniper
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Zongying
          language:
          - en
        - language:
          - en
          initial: Z
        formatted_initials:
          content: Z.
          language:
          - en
      surname:
        content: He
        language:
        - en
      completename:
        content: Zongying He
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Broadcom
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Junjie
          language:
          - en
        - language:
          - en
          initial: J
        formatted_initials:
          content: J.
          language:
          - en
      surname:
        content: Wang
        language:
        - en
      completename:
        content: Junjie Wang
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Centec
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Hongyi
          language:
          - en
        - language:
          - en
          initial: H
        formatted_initials:
          content: H.
          language:
          - en
      surname:
        content: Huang
        language:
        - en
      completename:
        content: Hongyi Huang
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Huawei
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Qingliang
          language:
          - en
        - language:
          - en
          initial: Q
        formatted_initials:
          content: Q.
          language:
          - en
      surname:
        content: Zhang
        language:
        - en
      completename:
        content: Qingliang Zhang
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: H3C
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Hang
          language:
          - en
        - language:
          - en
          initial: H
        formatted_initials:
          content: H.
          language:
          - en
      surname:
        content: Wu
        language:
        - en
      completename:
        content: Hang Wu
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Ruijie Networks
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Yadong
          language:
          - en
        - language:
          - en
          initial: "Y"
        formatted_initials:
          content: Y.
          language:
          - en
      surname:
        content: Liu
        language:
        - en
      completename:
        content: Yadong Liu
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Tencent
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Yinben
          language:
          - en
        - language:
          - en
          initial: "Y"
        formatted_initials:
          content: Y.
          language:
          - en
      surname:
        content: Xia
        language:
        - en
      completename:
        content: Yinben Xia
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Tencent
  role:
  - type: author
- person:
    name:
      given:
        forename:
        - content: Peilong
          language:
          - en
        - language:
          - en
          initial: P
        formatted_initials:
          content: P.
          language:
          - en
      surname:
        content: Wang
        language:
        - en
      completename:
        content: Peilong Wang
        language:
        - en
    affiliation:
    - organization:
        name:
        - content: Baidu
  role:
  - type: author
version:
- draft: '04'
revdate: '2025-05-21'
language:
- en
script:
- Latn
abstract:
- content: "<p>Large language models (LLMs) like ChatGPT have become increasingly
    popular in recent years due to their impressive performance in various natural
    language processing tasks. These models are built by training deep neural networks
    on massive amounts of text data, as well as visual and video data, often consisting
    of billions or even trillions of parameters. However, the training process for
    these models can be extremely resource-intensive, requiring the deployment of
    thousands or even tens of thousands of GPUs in a single AI training cluster. Therefore,
    three-stage or even five-stage CLOS networks are commonly adopted for AI networks.
    The non-blocking nature of the network become increasingly critical for large-scale
    AI models. Therefore, adaptive routing is necessary to dynamically distribute
    traffic to the same destination over multiple equal-cost paths, based on network
    capacity and even congestion information along those paths.</p>"
  language:
  - en
  script:
  - Latn
  format: text/html
relation:
- type: updates
  bibitem:
    id: draft-xu-lsr-fare-03
    docid:
    - id: draft-xu-lsr-fare-03
      type: Internet-Draft
      primary: true
    formattedref:
      content: draft-xu-lsr-fare-03
      format: text/plain
series:
- type: main
  title:
    content: Internet-Draft
    language:
    - en
    script:
    - Latn
    format: text/plain
  number: draft-xu-lsr-fare-04
doctype: internet-draft
ext:
  schema-version: v1.0.1
